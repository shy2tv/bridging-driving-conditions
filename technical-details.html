<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      Technical Details | Bridging Clear and Adverse Driving Conditions
    </title>
    <!-- OpenGraph meta tags for social media previews -->
    <meta
      property="og:title"
      content="Technical Details & Model Architecture"
    />
    <meta
      property="og:description"
      content="Detailed overview of our hybrid pipeline combining simulation, diffusion, and GANs for adverse-condition driving data."
    />
    <meta property="og:image" content="images/daunit-min.png" />
    <meta property="og:url" content="https://example.com/architecture.html" />
    <meta property="og:type" content="website" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css"
    />
    <link rel="stylesheet" href="css/styles.css" />
    <link rel="stylesheet" href="css/technical-details.css" />
    <link
      rel="icon"
      type="image/png"
      sizes="16x16"
      href="images/favicons/16x16.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="32x32"
      href="images/favicons/32x32.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="48x48"
      href="images/favicons/48x48.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="64x64"
      href="images/favicons/64x64.png"
    />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="navbar">
      <div class="navbar-content">
        <div class="navbar-brand">
          <a href="index.html" style="text-decoration: none; color: white">
            <h2>Bridging Clear and Adverse Driving</h2>
          </a>
        </div>
        <div class="nav-rail">
          <div class="nav-links">
            <a href="index.html">Home</a>
            <a href="index.html#demo">Demo</a>
            <a href="index.html#features">Key Features</a>
            <a href="technical-details.html" class="active"
              >Technical Details</a
            >
            <a href="key-insights.html">Key Insights</a>
            <a href="#contact">Contact</a>
            <a href="#" class="cta-button">arXiv</a>
          </div>
        </div>
        <div class="logo-container">
          <img src="images/Bosch-Logo.png" alt="Bosch Logo" />
        </div>
      </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero-section">
      <div class="hero-content">
        <h1>Technical Details</h1>
        <p>Our approach to bridging clear and adverse driving conditions</p>
      </div>
    </section>

    <!-- Main Content -->
    <div class="main-content">
      <!-- Pipeline Overview -->
      <section id="pipeline" class="section">
        <h2>Hybrid Pipeline Overview</h2>

        <div class="paper-summary">
          <h3>
            Three-Stage Generation Process&nbsp;(S&nbsp;→&nbsp;D&nbsp;→&nbsp;G)
          </h3>
          <p>
            We sculpt high-fidelity synthetic data first, then use it to
            translate <em>real-world</em> clear frames into adverse conditions:
          </p>

          <ul class="key-points">
            <li>
              <strong>S – Simulation:</strong>
              <span class="tooltip-container">
                CARLA<span class="info-icon">i</span>
                <span class="tooltip">
                  <strong>CARLA:</strong> Open-source autonomous driving
                  simulator providing high-fidelity synthetic images with
                  pixel-perfect labels.<br />
                  <a href="https://carla.org" target="_blank">Visit CARLA →</a>
                </span>
              </span>
              renders pixel-perfect clear/adverse pairs with full annotations.
            </li>

            <li>
              <strong>D – Diffusion:</strong>
              <span class="tooltip-container">
                Stable Diffusion<span class="info-icon">i</span>
                <span class="tooltip">
                  <strong>Stable Diffusion:</strong> Latent diffusion model for
                  high-detail image synthesis.<br />
                  <a
                    href="https://stability.ai/blog/stable-diffusion-announcement"
                    target="_blank"
                    >Learn more →</a
                  >
                </span>
              </span>
              /
              <span class="tooltip-container">
                ALDM<span class="info-icon">i</span>
                <span class="tooltip">
                  <strong>ALDM:</strong> Adaptive Latent Diffusion Model that
                  refines realism using segmentation guidance.<br />
                  <a href="https://arxiv.org/abs/2401.08815" target="_blank"
                    >View ALDM paper →</a
                  >
                </span>
              </span>
              boosts realism, guided by segmentation masks.
            </li>

            <li>
              <strong>G – GAN Adaptation:</strong>
              <span class="tooltip-container">
                DA-UNIT<span class="info-icon">i</span>
                <span class="tooltip">
                  <strong>DA-UNIT:</strong> Domain Adaptation with Unsupervised
                  Image-to-Image Translation Networks.<br />
                  <a href="https://arxiv.org/abs/2302.04149" target="_blank"
                    >View paper →</a
                  >
                </span>
              </span>
              learns on the curated <em>S + D</em> pairs plus a 10% mix of real
              <span class="tooltip-container">
                <strong>ACDC-Clear</strong><span class="info-icon">i</span>
                <span class="tooltip">
                  <strong>ACDC-Clear:</strong> Subset of the Adverse Conditions
                  Dataset containing clear-weather driving images.<br />
                  <a href="https://acdc.vision.ee.ethz.ch/" target="_blank"
                    >Visit ACDC →</a
                  >
                </span>
              </span>
              frames.
              <br />
              <strong>Inference:</strong> Feed any clear ACDC frame → DA-UNIT
              returns a photorealistic fog, rain, or night image with labels
              preserved.
            </li>
          </ul>
        </div>
      </section>

      <!-- Architecture Section -->
      <section id="architecture" class="section">
        <h2>Enhanced DA-UNIT Architecture</h2>
        <div class="architecture-image-container">
          <img
            src="images/daunit-min.png"
            alt="DA-UNIT model architecture diagram showing the enhanced GAN pipeline"
            class="architecture-image"
            loading="lazy"
          />
          <div class="zoom-icon"><i class="fas fa-expand"></i></div>
        </div>
        <div class="paper-summary">
          <h3>Key Architectural Improvements</h3>
          <ul class="key-points">
            <li>
              Support for depth, semantic, and instance data at encoder/decoder
              stages
            </li>
            <li>Improved object shape preservation through auxiliary inputs</li>
            <li>Enhanced label alignment with ground-truth data</li>
            <li>Novel training strategy combining simulated and real images</li>
          </ul>
        </div>
      </section>

      <!-- Fullscreen modal for the architecture image -->
      <div id="architecture-fullscreen" class="fullscreen-overlay">
        <div class="fullscreen-container">
          <button class="close-fullscreen">&times;</button>
          <img
            src="images/daunit-min.png"
            alt="Full-size DA-UNIT model architecture diagram showing encoder-decoder structure"
            loading="lazy"
          />
        </div>
      </div>

      <!-- Technical Details Section -->
      <section id="technical" class="section">
        <h2>Technical Details</h2>
        <div class="paper-summary">
          <h3>Blending Technique</h3>
          <p>
            Our novel blending approach addresses key challenges in the
            generation process:
          </p>
          <ul class="key-points">
            <li>
              Adaptive merging of diffusion output with original simulated
              images
            </li>
            <li>Mitigation of artifacts (e.g., distorted vehicles)</li>
            <li>
              Preservation of photorealistic enhancements (e.g., wet roads,
              nighttime lighting)
            </li>
          </ul>

          <h3>Training Strategy</h3>
          <p>The enhanced training process combines multiple data sources:</p>
          <ul class="key-points">
            <li>Simulation images for perfect pixel-level matching</li>
            <li>Unlabeled real images to close the simulation-to-real gap</li>
            <li>
              Auxiliary inputs (depth, semantic segmentation) for improved
              guidance
            </li>
          </ul>

          <h3>Performance Results</h3>
          <p>Performance highlights (ACDC):</p>
          <ul class="key-points">
            <li>
              <strong>78.57 %</strong> mIoU on <em>ACDC-Adverse (test)</em> —
              obtained with <u>zero</u> adverse-weather images in training.
            </li>

            <li>
              <strong>+1.85 %</strong> mIoU on <em>ACDC (val)</em> overall,
              versus the baseline
              <span class="baseline-note">
                (
                <span class="tooltip-container">
                  REIN<span class="info-icon">i</span>
                  <span class="tooltip">
                    <strong>REIN:</strong> Robust Enhancement via Instance
                    Normalization pre-trained on Cityscapes and fine-tuned on
                    ACDC-Clear.<br />
                    <a href="https://arxiv.org/abs/2312.04265" target="_blank"
                      >View Paper →</a
                    >
                  </span>
                </span>
                pre-trained on Cityscapes → finetuned on ACDC-Clear ) </span
              >.
            </li>

            <li>
              <strong>Night subset:</strong> +4.62 % mIoU on
              <em>ACDC-Night (val)</em> over the same baseline.
            </li>
          </ul>
        </div>
      </section>

      <!-- Applications Section -->
      <section id="applications" class="section">
        <h2>Applications</h2>
        <div class="paper-summary">
          <h3>Practical Benefits</h3>
          <ul class="key-points">
            <li>
              Cost-effective generation of adverse-condition training data
            </li>
            <li>Significant reduction in real-world data collection needs</li>
            <li>Improved robustness of autonomous perception systems</li>
            <li>
              Flexible adaptation to various adverse conditions (night, rain,
              fog, snow)
            </li>
          </ul>
        </div>
      </section>
    </div>

    <!-- Contact Section -->
    <section id="contact" class="contact-section">
      <h2>Our Team</h2>
      <div class="contact-grid">
        <div class="contact-card">
          <img
            src="images/profile_yoel.jpeg"
            alt="Yoel Shapiro"
            class="profile-image"
            loading="lazy"
          />
          <h3>Shapiro Yoel</h3>
          <p>Research Engineer</p>
          <a href="mailto:Yoel.Shapiro@il.bosch.com"
            >Yoel.Shapiro@il.bosch.com</a
          >
          <div class="contact-links">
            <a
              href="https://www.linkedin.com/in/yoel-shapiro-142abb21/"
              target="_blank"
              ><i class="fab fa-linkedin"></i>LinkedIn</a
            >
            <a
              href="https://scholar.google.com/citations?user=Ry_iQqEAAAAJ&hl=en"
              target="_blank"
              ><i class="fas fa-graduation-cap"></i>Scholar</a
            >
          </div>
        </div>
        <div class="contact-card">
          <img
            src="images/profile_yahia_2_cropped.jpg"
            alt="Yahia Showgan"
            class="profile-image"
            loading="lazy"
          />
          <h3>Yahia Showgan</h3>
          <p>Computer Vision Researcher</p>
          <a href="mailto:YahiaShowgan@gmail.com">YahiaShowgan@gmail.com</a>
          <div class="contact-links">
            <a href="https://www.linkedin.com/in/yahia-showgan/" target="_blank"
              ><i class="fab fa-linkedin"></i>LinkedIn</a
            >
            <a
              href="https://scholar.google.com/citations?user=Ry_iQqEAAAAJ&hl=en"
              target="_blank"
              ><i class="fas fa-graduation-cap"></i>Scholar</a
            >
          </div>
        </div>
        <div class="contact-card">
          <img
            src="images/profile_koustav.png"
            alt="Koustav Mullick"
            class="profile-image"
            loading="lazy"
          />
          <h3>Mullick Koustav</h3>
          <p>Computer Vision Researcher</p>
          <a href="mailto:Koustav.Mullick@in.bosch.com"
            >Koustav.Mullick@in.bosch.com</a
          >
          <div class="contact-links">
            <a href="https://www.linkedin.com/in/kmul00/" target="_blank"
              ><i class="fab fa-linkedin"></i>LinkedIn</a
            >
            <a
              href="https://scholar.google.com/citations?user=lP2FUZ0AAAAJ&hl=en"
              target="_blank"
              ><i class="fas fa-graduation-cap"></i>Scholar</a
            >
          </div>
        </div>
      </div>
      <div class="acknowledgement">
        <p>
          This research is supported by Bosch Research and Technology Center.
        </p>
        <img
          src="images/Bosch-Logo.png"
          alt="Bosch Logo"
          class="acknowledgement-logo"
          loading="lazy"
        />
      </div>
    </section>

    <!-- Footer -->
    <footer>
      <p>
        &copy; 2025 Bridging Clear and Adverse Driving Research Team. All rights
        reserved.
      </p>
    </footer>

    <!-- Add JavaScript at the end of the file -->
    <script src="js/technical-details.js"></script>
    <script src="js/main.js"></script>
  </body>
</html>
