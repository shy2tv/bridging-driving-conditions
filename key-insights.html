<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Key Insights | Bridging Clear and Adverse Driving Conditions</title>
    <!-- OpenGraph meta tags for social media previews -->
    <meta
      property="og:title"
      content="Key Insights - Bridging Clear and Adverse Driving Conditions"
    />
    <meta
      property="og:description"
      content="Key insights and findings from our research on domain adaptation for adverse driving conditions."
    />
    <meta property="og:image" content="images/Bosch-Cover.jpg" />
    <meta property="og:url" content="https://example.com/key-insights.html" />
    <meta property="og:type" content="website" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css"
    />
    <link rel="stylesheet" href="css/styles.css" />
    <link rel="stylesheet" href="css/key-insights.css" />
    <link
      rel="icon"
      type="image/png"
      sizes="16x16"
      href="images/favicons/16x16.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="32x32"
      href="images/favicons/32x32.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="48x48"
      href="images/favicons/48x48.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="64x64"
      href="images/favicons/64x64.png"
    />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="navbar">
      <div class="navbar-content">
        <div class="navbar-brand">
          <a href="index.html" style="text-decoration: none; color: white">
            <h2>Bridging Clear and Adverse Driving</h2>
          </a>
        </div>
        <div class="nav-rail">
          <div class="nav-links">
            <a href="index.html">Home</a>
            <a href="index.html#demo">Demo</a>
            <a href="index.html#features">Key Features</a>
            <a href="technical-details.html">Technical Details</a>
            <a href="key-insights.html" class="active">Key Insights</a>
            <a href="#contact">Contact</a>
            <a
              href="https://arxiv.org/"
              class="cta-button"
              target="_blank"
              rel="noopener noreferrer"
            >
              arXiv
            </a>
          </div>
        </div>
        <div class="logo-container">
          <img src="images/Bosch-Logo.png" alt="Bosch Logo" />
        </div>
      </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero-section">
      <div class="hero-content">
        <h1>Key Insights</h1>
        <p>Discover the most important findings from our research</p>
      </div>
    </section>

    <!-- Main Content -->
    <div class="main-content">
      <!-- Key Insights Overview -->
      <!-- Key Insights Overview -->

      <section id="overview" class="section">
        <h2>Research Insights</h2>

        <p class="overview-intro">
          After showing that <strong>SDG-DA</strong> can generate fog, rain,
          snow, and night scenes without any real adverse-weather examples, we
          distilled four core insights that explain how and why our pipeline
          works—and how you can leverage it immediately.
        </p>

        <div class="paper-summary">
          <h3>Major Findings</h3>
          <ul class="key-points">
            <li>
              <strong>Zero-Shot Performance:</strong> Our pipeline generates
              photorealistic adverse-condition images that boost semantic
              segmentation to <strong>78.57% mIoU</strong> on ACDC-all without
              using any real adverse-weather training data.
            </li>
            <li>
              <strong>Simulation-to-Real Gap:</strong> Combining CARLA
              simulation with diffusion models bridges the synthetic→real domain
              gap.
            </li>
            <li>
              <strong>Label Preservation:</strong> Enhanced DA-UNIT preserves
              pixel-perfect semantic labels while generating photorealistic fog,
              rain, snow, and night.
            </li>
            <li>
              <strong>Data Reusability:</strong> Generated adverse-condition
              images are task-agnostic—use them for detection, segmentation, or
              any vision task.
            </li>
            <li>
              <strong>Operational Efficiency:</strong> Our pipeline drastically
              reduces costly real-world adverse-data collection and labeling.
            </li>
          </ul>
        </div>
      </section>

      <!-- Key Research Findings with Images -->
      <section id="key-findings" class="section">
        <h2>Key Research Discoveries</h2>

        <!-- Object Size Distribution Finding -->
        <div class="insight-card">
          <div class="insight-content">
            <h3>Size Distribution Challenges</h3>
            <p>
              We were surprised to find that detection AP on certain ACDC
              adverse-weather splits (e.g. fog) actually exceeded the score on
              clear-weather images—despite the harsher conditions (lower
              visibility).
            </p>
            <p>
              A closer look at object-size distributions revealed the reason:
              adverse scenes are dominated by larger, easier detect objects,
              while clear scenes contain a much higher share of small, difficult
              instances. This small-object bias in the “easy” clear data
              explains why the models performs better on some adverse splits.
            </p>
            <p>
              This insight helped us optimize our pipeline to better handle the
              full range of object sizes, improving overall robustness across
              all weather conditions.
            </p>
          </div>
          <div class="insight-image">
            <img
              src="images/object_size_distribution.jpg"
              alt="Object size distribution across weather conditions"
              class="insight-img"
            />
            <div class="zoom-icon"><i class="fas fa-expand"></i></div>
            <p class="image-caption">
              Figure: Distribution of object sizes (√area) across different
              weather conditions. Clear weather (yellow) has significantly more
              small objects than adverse conditions.
            </p>
          </div>
        </div>

        <!-- ── Cross-Weather Transfer Insight ── -->
        <div class="insight-card">
          <div class="insight-content">
            <h3>Cross-Weather Transfer</h3>
            <p>
              We trained on a single adverse condition and evaluated across all
              others. Below is our real-data credit-assignment table: the best
              in each column is <strong>bolded</strong> and the row headers
              highlight which split was used.
            </p>
          </div>
          <div class="insight-content table-container">
            <table class="credit-assignment">
              <caption class="visually-hidden">
                Real data credit assignment
              </caption>
              <thead>
                <tr>
                  <!-- empty corner cell -->
                  <th scope="col"></th>
                  <!-- group header over all test columns -->
                  <th scope="colgroup" colspan="7" style="text-align: center">
                    Evaluated On
                  </th>
                </tr>
                <tr>
                  <th scope="row" style="text-align: center">Trained On</th>
                  <th scope="col">Fog</th>
                  <th scope="col">Rain</th>
                  <th scope="col">Night</th>
                  <th scope="col">Snow</th>
                  <th scope="col">Clear</th>
                  <th scope="col">Adverse</th>
                  <th scope="col">All</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><em>ACDC-clear + Fog</em></td>
                  <td class="highlight">44.60</td>
                  <td class="highlight">31.86</td>
                  <td class="highlight">21.76</td>
                  <td class="highlight">39.78</td>
                  <td><strong>32.31</strong></td>
                  <td>33.69</td>
                  <td>33.28</td>
                </tr>
                <tr>
                  <td><em>ACDC-clear + Rain</em></td>
                  <td class="highlight">51.06</td>
                  <td class="highlight"><strong>35.86</strong></td>
                  <td class="highlight">21.53</td>
                  <td class="highlight">40.96</td>
                  <td>31.68</td>
                  <td><strong>36.29</strong></td>
                  <td><strong>34.61</strong></td>
                </tr>
                <tr>
                  <td><em>ACDC-clear + Night</em></td>
                  <td class="highlight">46.15</td>
                  <td class="highlight">32.36</td>
                  <td class="highlight"><strong>24.50</strong></td>
                  <td class="highlight">37.44</td>
                  <td>32.02</td>
                  <td>34.09</td>
                  <td>33.51</td>
                </tr>
                <tr>
                  <td><em>ACDC-clear + Snow</em></td>
                  <td class="highlight"><strong>51.35</strong></td>
                  <td class="highlight">34.18</td>
                  <td class="highlight">21.78</td>
                  <td class="highlight"><strong>44.48</strong></td>
                  <td>31.86</td>
                  <td>35.33</td>
                  <td>33.73</td>
                </tr>
                <tr>
                  <td><em>ACDC-clear + All</em></td>
                  <td>53.02</td>
                  <td>36.14</td>
                  <td>25.59</td>
                  <td>47.02</td>
                  <td>32.31</td>
                  <td>39.05</td>
                  <td>36.43</td>
                </tr>
              </tbody>
            </table>

            <p>
              <br />
              This reveals that training exclusively on any single weather
              condition does not guarantee the best performance on that same
              condition—models trained on other splits can actually outperform
              the “matched” model when evaluated under the same scenario. <br />
            </p>
          </div>
        </div>

        <!-- ── Category Distribution (Pie) Insight ── -->
        <div class="insight-card">
          <div class="insight-content">
            <h3>Object Category Distribution</h3>
            <p>
              Different weather conditions introduce different category biases—
              here's a breakdown of how objects are distributed. Notice how
              clear vs. nighttime scenes contain proportionally more small,
              vulnerable categories (bicycles, motorcycles).
            </p>
          </div>
          <div class="insight-image">
            <img
              src="images/object_category_dist.png"
              alt="Object category distribution across weather conditions"
              class="insight-img"
            />
            <div class="zoom-icon"><i class="fas fa-expand"></i></div>
            <p class="image-caption">
              Figure: Object category distribution varies significantly across
              weather conditions, with clear and nighttime containing more
              difficult objects (e.g., bicycles, motorcycles).
            </p>
          </div>
        </div>

        <!-- Auxiliary Input Types Comparison Finding -->
        <div class="insight-card">
          <div class="insight-content">
            <h3>Auxiliary Inputs Matter</h3>
            <p>
              Our enhanced DA-UNIT architecture accepts depth maps, semantic
              segmentation, and instance segmentation as auxiliary inputs. These
              inputs significantly improve object preservation during domain
              adaptation.
            </p>
            <p>
              Different configurations of auxiliary inputs have distinctive
              effects on the generated images, with depth maps at the encoder
              stage providing the best balance of realism and object integrity.
            </p>
          </div>
          <div class="insight-image">
            <img
              src="images/aux_input_types_comparison-thumb.jpg"
              data-fullsrc="images/aux_input_types_comparison.png"
              alt="Comparison of different auxiliary input types"
              class="insight-img"
              loading="lazy"
            />
            <div class="zoom-icon"><i class="fas fa-expand"></i></div>
            <p class="image-caption">
              Figure: Comparison of generation results with different auxiliary
              input types. Left column shows clear input, right columns show
              outputs with different auxiliary inputs.
            </p>
          </div>
        </div>

        <!-- ControlNet Blending Finding -->
        <div class="insight-card">
          <div class="insight-content">
            <h3>Adaptive Blending Technique</h3>
            <p>
              Our novel blending approach addresses hallucinations and artifacts
              in diffusion outputs by adaptively combining the best parts of
              CARLA simulations with diffusion-enhanced regions.
            </p>
            <p>
              We discovered that different object categories benefit from
              different blending weights: vehicles and traffic lights work best
              with low diffusion influence (0.1), while static background
              elements like roads benefit from higher diffusion influence (0.8).
            </p>
          </div>
          <div class="insight-image">
            <img
              src="images/controlnet_blending-thumb.jpg"
              data-fullsrc="images/controlnet_blending.png"
              alt="ControlNet blending technique visualization"
              class="insight-img"
              loading="lazy"
            />
            <div class="zoom-icon"><i class="fas fa-expand"></i></div>
            <p class="image-caption">
              Figure: Our blending technique removes artifacts while preserving
              photorealism. Left to right: semantic segmentation, CARLA
              simulation, diffusion output, and final blended result.
            </p>
          </div>
        </div>
      </section>

      <!-- Impact Section -->
      <section id="impact" class="section">
        <h2>Research Impact</h2>
        <div class="paper-summary">
          <h3>Practical Applications</h3>
          <ul class="key-points">
            <li>
              <strong>Autonomous Driving:</strong> Enhances perception-system
              robustness across a wide range of adverse weather conditions.
            </li>
            <li>
              <strong>Task-Agnostic Data:</strong> Generated adverse-condition
              images can be reused for any downstream vision task (detection,
              segmentation, depth, etc.), not just semantic segmentation.
            </li>
            <li>
              <strong>Model Training:</strong> Introduces a domain-adaptation
              strategy that preserves both semantic labels and fine-grained
              details during style transfer.
            </li>
            <li>
              <strong>Industry Integration:</strong> A modular, plugin-style
              pipeline that can slot into existing autonomous-driving toolchains
              with minimal retraining.
            </li>
          </ul>
        </div>
      </section>

      <!-- Future Directions -->
      <!-- <section id="future" class="section">
        <h2>Future Directions</h2>
        <div class="paper-summary">
          <h3>Research Opportunities</h3>
          <ul class="key-points">
            <li>
              <strong>Multi-Modal Integration:</strong> Exploring the
              incorporation of additional sensor data (LiDAR, radar) for
              enhanced robustness.
            </li>
            <li>
              <strong>Dynamic Weather Conditions:</strong> Extending the model
              to handle time-varying weather conditions and transitions.
            </li>
            <li>
              <strong>Real-Time Adaptation:</strong> Developing methods for
              on-the-fly domain adaptation in changing weather conditions.
            </li>
            <li>
              <strong>Cross-Dataset Generalization:</strong> Investigating the
              model's performance across different driving datasets and
              scenarios.
            </li>
          </ul>
        </div>
      </section> -->
    </div>

    <!-- Contact Section -->
    <section id="contact" class="contact-section">
      <h2>Our Team</h2>
      <div class="contact-grid">
        <div class="contact-card">
          <img
            src="images/profile_yoel.jpeg"
            alt="Yoel Shapiro"
            class="profile-image"
            loading="lazy"
          />
          <h3>Shapiro Yoel</h3>
          <p>Research Engineer</p>
          <a href="mailto:Yoel.Shapiro@il.bosch.com"
            >Yoel.Shapiro@il.bosch.com</a
          >
          <div class="contact-links">
            <a
              href="https://www.linkedin.com/in/yoel-shapiro-142abb21/"
              target="_blank"
            >
              <i class="fab fa-linkedin"></i>LinkedIn
            </a>
            <a
              href="https://scholar.google.com/citations?user=Ry_iQqEAAAAJ&hl=en"
              target="_blank"
            >
              <i class="fas fa-graduation-cap"></i>Scholar
            </a>
          </div>
        </div>
        <div class="contact-card">
          <img
            src="images/profile_yahia_2_cropped.jpg"
            alt="Yahia Showgan"
            class="profile-image"
            loading="lazy"
          />
          <h3>Yahia Showgan</h3>
          <p>Computer Vision Researcher</p>
          <a href="mailto:YahiaShowgan@gmail.com">YahiaShowgan@gmail.com</a>
          <div class="contact-links">
            <a
              href="https://www.linkedin.com/in/yahia-showgan/"
              target="_blank"
            >
              <i class="fab fa-linkedin"></i>LinkedIn
            </a>
            <a
              href="https://scholar.google.com/citations?user=Ry_iQqEAAAAJ&hl=en"
              target="_blank"
            >
              <i class="fas fa-graduation-cap"></i>Scholar
            </a>
          </div>
        </div>
        <div class="contact-card">
          <img
            src="images/profile_koustav.png"
            alt="Koustav Mullick"
            class="profile-image"
            loading="lazy"
          />
          <h3>Mullick Koustav</h3>
          <p>Computer Vision Researcher</p>
          <a href="mailto:Koustav.Mullick@in.bosch.com"
            >Koustav.Mullick@in.bosch.com</a
          >
          <div class="contact-links">
            <a href="https://www.linkedin.com/in/kmul00/" target="_blank">
              <i class="fab fa-linkedin"></i>LinkedIn
            </a>
            <a
              href="https://scholar.google.com/citations?user=lP2FUZ0AAAAJ&hl=en"
              target="_blank"
            >
              <i class="fas fa-graduation-cap"></i>Scholar
            </a>
          </div>
        </div>
      </div>
      <div class="acknowledgement">
        <p>
          This research is supported by Bosch Research and Technology Center.
        </p>
        <img
          src="images/Bosch-Logo.png"
          alt="Bosch Logo"
          class="acknowledgement-logo"
          loading="lazy"
        />
      </div>
    </section>

    <!-- Footer -->
    <footer>
      <p>
        &copy; 2025 Bridging Clear and Adverse Driving Research Team. All rights
        reserved.
      </p>
    </footer>

    <!-- Fullscreen modal for images -->
    <div id="image-fullscreen" class="fullscreen-overlay">
      <div class="fullscreen-container">
        <button class="close-fullscreen"><i class="fas fa-times"></i></button>
        <img src="" alt="Full-size image" />
      </div>
    </div>

    <script src="js/main.js"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function () {
        // Always keep Key Insights highlighted on this page
        const keyInsightsLink = document.querySelector(
          '.nav-links a[href="key-insights.html"]'
        );
        if (keyInsightsLink) {
          keyInsightsLink.classList.add("active");
        }

        // For section tracking - only affects other links, not Key Insights
        const sections = document.querySelectorAll("section[id]");
        const sectionLinks = document.querySelectorAll(
          '.nav-links a[href^="#"]:not([href="#"])'
        );

        // Update active section link based on scroll position
        function updateActiveSection() {
          let currentSectionId = "";

          sections.forEach((section) => {
            const sectionTop = section.offsetTop - 100;
            const sectionHeight = section.offsetHeight;
            if (
              window.scrollY >= sectionTop &&
              window.scrollY < sectionTop + sectionHeight
            ) {
              currentSectionId = "#" + section.getAttribute("id");
            }
          });

          // Update section links besides Key Insights
          sectionLinks.forEach((link) => {
            link.classList.toggle(
              "active",
              link.getAttribute("href") === currentSectionId
            );
          });

          // Always keep Key Insights highlighted
          if (keyInsightsLink) {
            keyInsightsLink.classList.add("active");
          }
        }

        // Listen for scroll events to update active section
        window.addEventListener("scroll", updateActiveSection);

        // Image zoom functionality
        const insightImages = document.querySelectorAll(".insight-img");
        const zoomIcons = document.querySelectorAll(".zoom-icon");
        const fullscreenOverlay = document.getElementById("image-fullscreen");
        const fullscreenImg = fullscreenOverlay.querySelector("img");
        const closeFullscreen =
          fullscreenOverlay.querySelector(".close-fullscreen");

        function openFullscreen(imgSrc) {
          fullscreenImg.src = imgSrc;
          fullscreenOverlay.style.display = "block";
        }

        function closeFullscreenHandler() {
          fullscreenOverlay.style.display = "none";
        }

        insightImages.forEach((img) => {
          img.addEventListener("click", () => {
            const full = img.dataset.fullsrc || img.src;
            openFullscreen(full);
          });
        });

        zoomIcons.forEach((icon) => {
          icon.addEventListener("click", (e) => {
            e.stopPropagation();
            const img = icon.previousElementSibling;
            const full = img.dataset.fullsrc || img.src;
            openFullscreen(full);
          });
        });

        closeFullscreen.addEventListener("click", closeFullscreenHandler);

        fullscreenOverlay.addEventListener("click", function (e) {
          if (
            e.target === fullscreenOverlay ||
            e.target.classList.contains("fullscreen-container")
          ) {
            closeFullscreenHandler();
          }
        });

        document.addEventListener("keydown", function (e) {
          if (e.key === "Escape") {
            closeFullscreenHandler();
          }
        });

        // Section tracking
        const scrollSections = document.querySelectorAll("section[id]");
        const navLinks = document.querySelectorAll(".nav-links a");
        const currentPageLink = document.querySelector(
          '.nav-links a[href="key-insights.html"]'
        );

        window.addEventListener("scroll", () => {
          let current = "";
          scrollSections.forEach((section) => {
            const sectionTop = section.offsetTop;
            const sectionHeight = section.clientHeight;
            if (pageYOffset >= sectionTop - 60) {
              current = section.getAttribute("id");
            }
          });

          navLinks.forEach((link) => {
            link.classList.remove("active");
            if (link.getAttribute("href") === `#${current}`) {
              link.classList.add("active");
            }
          });

          // If contact section is not in view, ensure the current page link is active
          if (current !== "contact" && currentPageLink) {
            currentPageLink.classList.add("active");
          }
        });
      });
    </script>
  </body>
</html>
